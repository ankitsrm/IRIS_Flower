{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozLQkp19o1o4"
   },
   "source": [
    "__Group No : 179__<br>\n",
    "__Group Members:__\n",
    "1. Priyadharishini NM \n",
    "2. Ankit Utkarsh\n",
    "3. Manish Agarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NQQ2xpVo3yF"
   },
   "source": [
    "Dataset Description: The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.\n",
    "\n",
    "The dataset has 150 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "    Sepal length in cm.\n",
    "    Sepal width in cm.\n",
    "    Petal length in cm.\n",
    "    Petal width in cm.\n",
    "    Class Species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSURNNXi6xS6"
   },
   "source": [
    "# **Load the dataset and describe it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ACK1yld0JicY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c254707a820a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import operator\n",
    "\n",
    "dataset = px.data.iris()\n",
    "x = dataset.iloc[:, :4].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "g8J4lg5IYCvm",
    "outputId": "583bce26-7458-4f73-e378-a65a82d4b3fe"
   },
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z7Tu4ejTdMJ"
   },
   "source": [
    "***Checking for missing values***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RP5iwWyWTVbu",
    "outputId": "eec0dfd2-8641-4221-a79e-f96104db6978"
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkx9epM8UOHq",
    "outputId": "0888bd05-b563-4016-eead-235244cac8db"
   },
   "outputs": [],
   "source": [
    "dataset['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgB1adm7Uc2y"
   },
   "source": [
    "This data set has three varities of Iris Plant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJs7Yg7nscrI"
   },
   "source": [
    "# **The Elbow Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "atcq5hYJmqAU",
    "outputId": "faca3862-547f-4746-c264-5e2b02d6c466"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wcss=[] \n",
    "for i in range (1,11):\n",
    "  kmeans= KMeans(n_clusters = i, init= 'k-means++', max_iter=300, n_init=10, random_state = 0)\n",
    "  kmeans.fit(x)\n",
    "  wcss.append(kmeans.inertia_)\n",
    "\n",
    "#Plotting the result \n",
    "plt.plot(range(1,11), wcss)\n",
    "plt.title(\"The ELBOW METHOD\")\n",
    "plt.xlabel(\"NUMBER OF ClUSTER\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLD_IyeusE6f"
   },
   "source": [
    "# ***HUE PLOT***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "id": "8fL4UQGyqoi3",
    "outputId": "9d6e6ed7-1b1a-4bb9-aa32-35bba9d565cc"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(dataset, hue = \"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtgrAFzArpNO"
   },
   "source": [
    "'HUE' and 'ELBOW' method clearly shows that its operates in cluster and for this we need 3 Cluster for KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yplnLGTY6wRl"
   },
   "source": [
    "# **Split the data as per 80:20 ratios of training and test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWgH-CM6zZw8",
    "outputId": "ff344167-6b09-4d6d-f1be-c440763c34a9"
   },
   "outputs": [],
   "source": [
    "dataset['species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0d6qz4Z7VRa"
   },
   "source": [
    "Getting unique values of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El7xfMAJ7csQ"
   },
   "source": [
    "***Establishing Y Variable***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "F7uCK_7rzxsq",
    "outputId": "1f7745bb-8ceb-4fe4-e31d-f8bcbe36f202"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEnc= LabelEncoder()\n",
    "\n",
    "dataset['Code'] = labelEnc.fit_transform(dataset['species'])\n",
    "dataset_code = dataset.drop(\"species\", axis =1)\n",
    "\n",
    "dataset_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBWXRRTQ7lNg"
   },
   "source": [
    "*Modeling -- Scaling the data by using sklearn lib*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMDSbSXYwDGN"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset_code.drop([\"Code\"],axis = 1))\n",
    "\n",
    "scaled_feat = scaler.transform(dataset_code.drop([\"Code\"], axis =1))\n",
    "dataset_feat = pd.DataFrame(scaled_feat, columns = dataset_code.columns[:-1])\n",
    "x= dataset_feat\n",
    "y=dataset_code[\"Code\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6SSzpFs8ALG"
   },
   "source": [
    "*Spliting the dataset for training and testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnjwRihutB14",
    "outputId": "9eebce8f-19f9-4afd-d08e-adc8e9e93758"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "x_train, X_test, y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 360)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(x_train,y_train)\n",
    "print(\"There are {} samples in the training set and {} samples in th e test set\". format(x_train.shape[0], X_test.shape[0]))\n",
    "print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fA-8zvE3Rrt"
   },
   "outputs": [],
   "source": [
    "predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zKtReTI3d9r",
    "outputId": "cccd1f4e-a75a-49a3-aba8-b95f8a878748"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print (confusion_matrix(Y_test, predict))\n",
    "print (classification_report(Y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4lgcOR98JEh"
   },
   "source": [
    "# **Normalize the dataset. Visualize the dataset before and after normalization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUd7ae7HTIok"
   },
   "source": [
    "Data visualization before dataset. We are trying to visualise the data by Statistically as well as Andrews Curve As we have mulitidimensional Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RS-mFq3pkmWn"
   },
   "source": [
    "Describing the data : Below Plot gives us a general idea about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "IknEtn5oka5Q",
    "outputId": "94753734-095f-4e2b-abb9-8f08aa7d4cad"
   },
   "outputs": [],
   "source": [
    "dataset.describe().plot(kind = \"area\", fontsize = 10, figsize = (20,8), table = True, colormap = \"rainbow\")\n",
    "plt.xlabel(\"Statistics\",)\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Genral Statistics of Irsi Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5RsMyc3TQYg"
   },
   "source": [
    "ANDREWS CURVE : It help to visualize structure in high dimensional data.Here each mulivariate observation is transformed into a curve and represent the coefficient of a fourier servies.\n",
    "This is use fil for detecting outlier in times series data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "ABi4i8XOW3IR",
    "outputId": "9a2d661d-168c-40e7-b986-481381c8d18d"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import andrews_curves\n",
    "plt.figure(figsize= (15,10))\n",
    "andrews_curves(dataset.drop(\"species_id\", axis=1), \"species\")\n",
    "plt.title(\"Andrews Curve Plot\", fontsize=20, fontweight = \"bold\")\n",
    "plt.legend(loc=1, prop={'size':15 }, frameon=True, shadow=True, facecolor=\"white\", edgecolor=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dspq5dDuniVv"
   },
   "source": [
    "# **Normalizing DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wzNPyFANIay3",
    "outputId": "edef7b52-30e0-4d27-e1f5-d9f8a8aa7106"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dataset_fn= dataset.copy()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "dataset_fn.iloc[:, [0,1,2,3,6]] = min_max_scaler.fit_transform(dataset_fn.iloc[:, [0,1,2,3,6]])\n",
    "dataset_fn.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyy-FG-fn8cJ"
   },
   "source": [
    "**Andrews Curve : After Normalizing DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "2ZRjsM7bF542",
    "outputId": "0e104034-3d18-49a9-b44f-e59232dd2585"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import andrews_curves\n",
    "plt.figure(figsize= (15,10))\n",
    "andrews_curves(dataset_fn.drop(\"species_id\", axis=1), \"species\")\n",
    "plt.title(\"Andrews Curve Plot\", fontsize=20, fontweight = \"bold\")\n",
    "plt.legend(loc=1, prop={'size':15 }, frameon=True, shadow=True, facecolor=\"white\", edgecolor=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxICYTP8oiRr"
   },
   "source": [
    "Statisticall : After Normalizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "zNx2IJN3L6dv",
    "outputId": "1e568fbc-f26b-4769-a29f-c01da24ca811"
   },
   "outputs": [],
   "source": [
    "dataset_fn.describe().plot(kind = \"area\", fontsize = 10, figsize = (20,8), table = True, colormap = \"rainbow\")\n",
    "plt.xlabel(\"Statistics\",)\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Genral Statistics of Irsi Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0E7fDMi7osi9"
   },
   "source": [
    "# Calculate Similarity based on distance function of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwy76MIp6sJH"
   },
   "source": [
    "***Mean and Standard Deviation of the \"Traing Set\" and \"Testing Set\" for computing normalized euclidean distance.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ga-y91_a8Q1U",
    "outputId": "873fdae9-dc35-4b05-f3f0-1c03b7f35e17"
   },
   "outputs": [],
   "source": [
    "mean_TrainingSet = x_train.mean()\n",
    "mean_TestSet = X_test.mean()\n",
    "std_TrainginSet = x_train.std()\n",
    "std_TestSet = X_test.std()\n",
    "print(\"=========Mean of Traingin DataSet=======\")\n",
    "print (mean_TrainingSet.head())\n",
    "print(\"=========Mean of Testing DataSet=====\")\n",
    "print (mean_TestSet.head())\n",
    "print(\"========Standard Deviation of Training DataSet==========\")\n",
    "print (std_TrainginSet.head())\n",
    "print(\"======Standard Deviation of Test DataSet===========\")\n",
    "print (std_TestSet.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIMEB7D7dkT3"
   },
   "outputs": [],
   "source": [
    "training_class=list(x_train.iloc[:, -1])\n",
    "test_class= list(X_test.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZJtFoTP8CWR"
   },
   "source": [
    "*We are using \"Normalized Euclidean Distance\" and \"Cosine Similarity\" for distance function.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEzYC6Zh74WT"
   },
   "outputs": [],
   "source": [
    "def normalizedEuclideanDistance(data_1, data_2, data_len, data_mean, data_std):\n",
    "    n_dist = 0\n",
    "    for i in range(data_len):\n",
    "        n_dist = n_dist + (np.square(((data_1[i] - data_mean[i])/data_std[i]) - ((data_2[i] - data_mean[i])/data_std[i])))\n",
    "    return np.sqrt(n_dist)\n",
    "\n",
    "def cosineSimilarity(data_1, data_2):\n",
    "    dot = np.dot(data_1, data_2[:-1])\n",
    "    norm_data_1 = np.linalg.norm(data_1)\n",
    "    norm_data_2 = np.linalg.norm(data_2[:-1])\n",
    "    cos = dot / (norm_data_1 * norm_data_2)\n",
    "    return (1-cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdc_Pjf-8EKo"
   },
   "source": [
    "# **Define a function to return k- nearest neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkGHVVlO8F5v"
   },
   "outputs": [],
   "source": [
    "def Knn_func(dataset, testInstance, k, dist_method, dataset_mean, dataset_std): \n",
    "    distances = {}\n",
    "    length = testInstance.shape[1]\n",
    "    if dist_method == 'normalized_euclidean':\n",
    "        for x in range(len(dataset)):\n",
    "            dist_up = normalizedEuclideanDistance(testInstance, dataset.iloc[x], length, dataset_mean, dataset_std)\n",
    "            distances[x] = dist_up[0]\n",
    "    elif dist_method == 'cosine':\n",
    "        for x in range(len(dataset)):\n",
    "            dist_up = cosineSimilarity(testInstance, dataset.iloc[x])\n",
    "            distances[x] = dist_up[0]\n",
    "    # Sort values based on distance\n",
    "    sort_distances = sorted(distances.items(), key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    # Extracting nearest k neighbors\n",
    "    for x in range(k):\n",
    "        neighbors.append(sort_distances[x][0])\n",
    "    # Initializing counts for 'class' labels counts as 0\n",
    "    counts = {\"Iris-setosa\" : 0, \"Iris-versicolor\" : 0, \"Iris-virginica\" : 0}\n",
    "    # Computing the most frequent class\n",
    "    for x in range(len(neighbors)):\n",
    "        response = dataset.iloc[neighbors[x]][-1] \n",
    "        if response in counts:\n",
    "            counts[response] += 1\n",
    "        else:\n",
    "            counts[response] = 1\n",
    "    # Sorting the class in reverse order to get the most frequest class\n",
    "    sort_counts = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return(sort_counts[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npnmGchO8Mhn"
   },
   "source": [
    "Using trainging data set which we splited above. Iterating all of the training set data points and computing the class of each k and each distance matric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lOgbsfO8NCx"
   },
   "outputs": [],
   "source": [
    "row_list=[]\n",
    "for index, rows in x_train.iterrows():\n",
    "  my_list= [rows.sepal_length, rows.sepal_width, rows.petal_length, rows.petal_width]\n",
    "  row_list.append([my_list])\n",
    "#k_n = [1, 3, 5, 6]\n",
    "k_n=[1,2,3,6]\n",
    "distance_methods = [ 'normalized_euclidean', 'cosine']\n",
    "obs_k={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEkgLlFOJa8d",
    "outputId": "d4adfd65-a81a-45e6-ca2a-e254d7b507c4"
   },
   "outputs": [],
   "source": [
    "for dist_method in distance_methods:\n",
    "  training_set_obs_k = {}\n",
    "  for k in k_n:\n",
    "    training_set_obs=[]\n",
    "    for i in range(len(row_list)):\n",
    "      training_set_obs.append(Knn_func(x_train, pd.DataFrame(row_list[i]), k, dist_method, mean_TrainingSet, std_TrainginSet))\n",
    "    training_set_obs_k[k]= training_set_obs\n",
    "  obs_k[dist_method] = training_set_obs_k\n",
    "  print(dist_method.upper() + \" Distance Method performed on all K values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH6QiLgewNKQ"
   },
   "source": [
    "Accuracy on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "O3IoTm8OS4j7",
    "outputId": "99134e74-6671-4dea-d7da-22af68f73c02"
   },
   "outputs": [],
   "source": [
    "accuracy = {}\n",
    "for key in obs_k.keys():\n",
    "    accuracy[key] = {}\n",
    "    for k_value in obs_k[key].keys():\n",
    "        #print('k = ', key)\n",
    "        count = 0\n",
    "        for i,j in zip(training_class, obs_k[key][k_value]):\n",
    "            if i == j:\n",
    "                count = count + 1\n",
    "            else:\n",
    "                pass\n",
    "        accuracy[key][k_value] = count/(len(training_class))\n",
    "\n",
    "# Storing the accuracy for each k and each distance metric into a dataframe\n",
    "df_res = pd.DataFrame({'k': k_n})\n",
    "for key in accuracy.keys():\n",
    "    value = list(accuracy[key].values())\n",
    "    df_res[key] = value\n",
    "print(df_res)\n",
    "\n",
    "# Plotting a Bar Chart for accuracy\n",
    "draw = df_res.plot(x='k', y=[ 'normalized_euclidean', 'cosine'], kind=\"bar\", colormap='YlGnBu')\n",
    "draw.set(ylabel='Accuracy')\n",
    "\n",
    "# Ignoring k=1 if the value of accuracy for k=1 is 100%, since this mostly implies overfitting\n",
    "df_res.loc[df_res['k'] == 1.0, ['normalized_euclidean', 'cosine']] = np.nan\n",
    "\n",
    "# Fetching the best k value for using all hyper-parameters\n",
    "# In case the accuracy is the same for different k and different distance metric selecting the first of all the same\n",
    "column_val = [c for c in df_res.columns if not c.startswith('k')]\n",
    "col_max = df_res[column_val].max().idxmax(0)\n",
    "best_dist_method = col_max\n",
    "row_max = df_res[col_max].argmax()\n",
    "best_k = int(df_res.iloc[row_max]['k'])\n",
    "if df_res.isnull().values.any():\n",
    "    print('\\n\\n\\nBest k value is\\033[1m', best_k, '\\033[0mand best distance metric is\\033[1m', best_dist_method, '\\033[0m. Ignoring k=1 if the value of accuracy for k=1 is 100%, since this mostly implies overfitting')\n",
    "else:\n",
    "    print('\\n\\n\\nBest k value is\\033[1m', best_k, '\\033[0mand best distance metric is\\033[1m', best_dist_method, '\\033[0m.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRqzx8DcT72S",
    "outputId": "118876de-e463-485e-e2f5-cf9fcf68b016"
   },
   "outputs": [],
   "source": [
    "print('\\n\\n\\nBest k value is\\033[1m', best_k, '\\033[0mand best distance metric is\\033[1m', best_dist_method, '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knMaFHekw4cg"
   },
   "source": [
    "# **Test the KNN Algorithm on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDof-F2GT_SW",
    "outputId": "b2300b88-f828-4080-83f2-b06a1729201e"
   },
   "outputs": [],
   "source": [
    "row_list_test = []\n",
    "for index, rows in X_test.iterrows(): \n",
    "    my_list =[rows.sepal_length, rows.sepal_width, rows.petal_length, rows.petal_width]       \n",
    "    row_list_test.append([my_list])\n",
    "test_set_obs = []\n",
    "for i in range(len(row_list_test)):\n",
    "    test_set_obs.append(Knn_func(X_test, pd.DataFrame(row_list_test[i]), best_k, best_dist_method,mean_TestSet, std_TestSet))\n",
    "#print(test_set_obs)\n",
    "\n",
    "count = 0\n",
    "for i,j in zip(test_class, test_set_obs):\n",
    "    if i == j:\n",
    "        count = count + 1\n",
    "    else:\n",
    "        pass\n",
    "accuracy_test = count/(len(test_class))\n",
    "print('Final Accuracy of the Test dataset is ', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNWcuP3ktU7l"
   },
   "source": [
    "# Perform hyper-parameter tuning using K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PsTBOIyoscy"
   },
   "outputs": [],
   "source": [
    "# sensitivity analysis of k in k-fold cross-validation\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "G1oGC00poGTV",
    "outputId": "05efa5d8-fb4b-4849-c539-4007c5ee29c7"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\tmodel = KNeighborsClassifier()\n",
    "\treturn model\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv):\n",
    "\t# get the dataset\n",
    "\t# get the model\n",
    "\tmodel = get_model()\n",
    "\t# evaluate the model\n",
    "\tscores = cross_val_score(model, X_test, Y_test, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# return scores\n",
    "\treturn mean(scores), scores.min(), scores.max()\n",
    " \n",
    "# calculate the ideal test condition\n",
    "ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "print('Ideal: %.3f' % ideal)\n",
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs = list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "\t# define the test condition\n",
    "\tcv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "\t# evaluate k value\n",
    "\tk_mean, k_min, k_max = evaluate_model(cv)\n",
    "\t# report performance\n",
    "\tprint('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "\t# store mean accuracy\n",
    "\tmeans.append(k_mean)\n",
    "\t# store min and max relative to the mean\n",
    "\tmins.append(k_mean - k_min)\n",
    "\tmaxs.append(k_max - k_mean)\n",
    "# line plot of k mean values with min/max error bars\n",
    "pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r')\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dxQKhaapziI"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "From the above , we can found that the by keeping any k value the accuracy is same.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fif35ReTqILv"
   },
   "source": [
    "# Use the test set and the optimal hyper-parameters to compute the final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neJURgDzp2mp",
    "outputId": "34092c35-0590-4849-f2bc-36e5201a1030"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(accuracy_score(Y_test, y_pred))\n",
    "print(classification_report(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HaB4-emqMZ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOeIAJYFrczy"
   },
   "source": [
    "The Accuracy od the Knn model is 100%. The Precision,Recall values is also 100%. So this is a very good model . The K value in KNN is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1q56gyYrwCS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ML_Assignment_IRISFlower.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
